import streamlit as st
import yfinance as yf
import requests
import pandas as pd
import datetime
import io
import re
from bs4 import BeautifulSoup
from deep_translator import GoogleTranslator

# ==========================================
# âš™ï¸ ç¶²é è¨­å®š
# ==========================================
st.set_page_config(page_title="å¸¥å“¥åŸ AI æŠ•é¡§", page_icon="ğŸ“ˆ", layout="wide")

# ==========================================
# ğŸ› ï¸ å·¥å…·å‡½å¼
# ==========================================
def translate_to_chinese(text):
    try:
        if not text or len(text) < 5: return "æš«ç„¡è©³ç´°æ¥­å‹™æè¿°ã€‚"
        return GoogleTranslator(source='auto', target='zh-TW').translate(text)
    except: return text

# å»ºç«‹ä¸€å€‹å…¨å±€çš„ Session ä¾†ç¶­æŒé€£ç·šç‹€æ…‹ (å°æŠ— Goodinfo)
session = requests.Session()
session.headers.update({
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
    "Accept-Language": "zh-TW,zh;q=0.9,en-US;q=0.8,en;q=0.7",
    "Referer": "https://goodinfo.tw/tw/StockDetail.asp"
})

# ==========================================
# ğŸ•µï¸â€â™‚ï¸ æ•¸æ“šç²å–å±¤
# ==========================================

def get_goodinfo_financials(stock_id):
    """
    [åŸºæœ¬é¢] å¼·åˆ¶çˆ¬å– Goodinfo è²¡å‹™æ•¸æ“š
    ç­–ç•¥ï¼šä½¿ç”¨ Session æ¨¡æ“¬é€£çºŒç€è¦½ï¼Œä¸¦å¢åŠ æ¬„ä½å®¹éŒ¯ç‡
    """
    clean_id = stock_id.replace(".TW", "").replace(".TWO", "")
    url = f"https://goodinfo.tw/tw/StockDetail.asp?STOCK_ID={clean_id}"
    
    try:
        # ç¬¬ä¸€æ¬¡è«‹æ±‚å¯èƒ½éœ€è¦æ‹¿ Cookie
        r = session.get(url, timeout=10)
        r.encoding = "utf-8"
        
        # æª¢æŸ¥æ˜¯å¦è¢«æ“‹ (å…§å®¹å¤ªå°‘å°±æ˜¯è¢«æ“‹)
        if len(r.text) < 1000:
            return None, "Goodinfo (Blocked)"
            
        dfs = pd.read_html(io.StringIO(r.text))
        data = {}
        
        # éæ­·è¡¨æ ¼æ‰¾é—œéµå­—
        for df in dfs:
            df_str = df.to_string()
            # å°‹æ‰¾åŒ…å«ç²åˆ©èƒ½åŠ›çš„è¡¨æ ¼
            if "æ¯›åˆ©ç‡" in df_str or "ROE" in df_str:
                # è½‰æˆæ–‡å­—å­—å…¸ä»¥ä¾¿æœç´¢
                text_map = {}
                for idx, row in df.iterrows():
                    for col in range(len(df.columns)-1):
                        k = str(row[col])
                        v = str(row[col+1])
                        text_map[k] = v
                
                def get_val(keywords):
                    for k, v in text_map.items():
                        if any(kw in k for kw in keywords):
                            # æ¸…æ´—æ•¸æ“šï¼Œåªç•™æ•¸å­—å’Œå°æ•¸é»
                            val = re.sub(r'[^\d.-]', '', v)
                            try:
                                return float(val)
                            except:
                                return None
                    return None

                # å˜—è©¦æŠ“å–
                data['GrossMargin'] = get_val(['æ¯›åˆ©ç‡'])
                data['OpMargin'] = get_val(['ç‡Ÿæ¥­åˆ©ç›Šç‡', 'ç‡Ÿç›Šç‡'])
                data['NetMargin'] = get_val(['ç¨…å¾Œæ·¨åˆ©ç‡', 'æ·¨åˆ©ç‡'])
                data['ROE'] = get_val(['è‚¡æ±æ¬Šç›Šå ±é…¬ç‡', 'ROE'])
                data['ROA'] = get_val(['è³‡ç”¢å ±é…¬ç‡', 'ROA'])
                data['EPS'] = get_val(['æ¯è‚¡ç¨…å¾Œç›ˆé¤˜', 'EPS', 'æ¯è‚¡ç›ˆé¤˜'])
                data['BPS'] = get_val(['æ¯è‚¡æ·¨å€¼'])
                
                # åªè¦æŠ“åˆ°ä¸€å€‹é—œéµæ•¸æ“šå°±ç®—æˆåŠŸ
                if data.get('GrossMargin') is not None:
                    return data, "Goodinfo"
                    
        return None, "Goodinfo (Parse Fail)"

    except Exception as e:
        print(f"Goodinfo Error: {e}")
        return None, "Goodinfo (Error)"

def get_histock_chips(stock_id):
    """
    [ç±Œç¢¼é¢] å¾ HiStock (å—¨æŠ•è³‡) æŠ“å–é›†ä¿åˆ†ä½ˆ
    ä¿®æ­£ï¼šä¸ä¾è³´ pd.read_htmlï¼Œæ”¹ç”¨ BeautifulSoup æ‰‹è¡“åˆ€è§£æ
    """
    clean_id = stock_id.replace(".TW", "").replace(".TWO", "")
    url = f"https://histock.tw/stock/large.aspx?no={clean_id}"
    
    try:
        r = session.get(url, timeout=10)
        soup = BeautifulSoup(r.text, 'html.parser')
        
        # HiStock çš„è¡¨æ ¼é€šå¸¸æœ‰ç‰¹å®šçš„ class æˆ–çµæ§‹
        # æˆ‘å€‘ç›´æ¥æ‰¾åŒ…å« "400å¼µ" çš„é‚£å€‹è¡¨æ ¼
        tables = soup.find_all('table')
        target_table = None
        
        for t in tables:
            if "400å¼µ" in t.text and "è‚¡æ±äººæ•¸" in t.text:
                target_table = t
                break
        
        if target_table:
            # æ‰¾åˆ°è¡¨æ ¼å¾Œï¼ŒæŠ“å–æ‰€æœ‰çš„ tr (åˆ—)
            rows = target_table.find_all('tr')
            # æ’é™¤æ¨™é¡Œåˆ—ï¼Œå–è³‡æ–™åˆ— (é€šå¸¸ç¬¬äºŒåˆ—é–‹å§‹æ˜¯æœ€æ–°ä¸€é€±)
            # rows[0] æ˜¯æ¨™é¡Œ, rows[1] æ˜¯æœ€æ–°é€±, rows[2] æ˜¯ä¸Šé€±
            if len(rows) >= 3:
                row_now = rows[1].find_all('td')
                row_prev = rows[2].find_all('td')
                
                # HiStock æ¬„ä½é †åºå¯èƒ½æœƒè®Šï¼Œä½†é€šå¸¸æ˜¯ï¼š
                # é€±åˆ¥ | æ”¶ç›¤åƒ¹ | ... | 400å¼µæ¯”ä¾‹ | ... | è‚¡æ±äººæ•¸ | ...
                
                # æˆ‘å€‘ç”¨ã€Œæ¬„ä½æ¨™é¡Œã€ä¾†å®šä½ index
                headers = [th.text.strip() for th in rows[0].find_all('th')]
                if not headers: # æœ‰æ™‚å€™æ˜¯ td
                    headers = [td.text.strip() for td in rows[0].find_all('td')]
                
                idx_big = -1
                idx_holders = -1
                idx_date = 0
                
                for i, h in enumerate(headers):
                    if "400å¼µ" in h and "%" in h: idx_big = i
                    if "äººæ•¸" in h: idx_holders = i
                    if "æœŸ" in h or "å‘¨" in h or "æ—¥" in h: idx_date = i
                
                if idx_big != -1 and idx_holders != -1:
                    # æŠ“æ•¸æ“š
                    curr_big = float(row_now[idx_big].text.replace('%', '').strip())
                    prev_big = float(row_prev[idx_big].text.replace('%', '').strip())
                    
                    curr_hold = int(row_now[idx_holders].text.replace(',', '').strip())
                    prev_hold = int(row_prev[idx_holders].text.replace(',', '').strip())
                    
                    date_str = row_now[idx_date].text.strip()
                    
                    return {
                        "source": "HiStock",
                        "date": date_str,
                        "big_percent": curr_big,
                        "big_change": curr_big - prev_big,
                        "holders": curr_hold,
                        "holders_change": curr_hold - prev_hold
                    }
    except Exception as e:
        print(f"HiStock Error: {e}")
        return None
    return None

def get_yahoo_web_scraper(stock_id):
    headers = { "User-Agent": "Mozilla/5.0" }
    try:
        url = f"https://tw.stock.yahoo.com/quote/{stock_id}"
        r = requests.get(url, headers=headers, timeout=5)
        soup = BeautifulSoup(r.text, 'html.parser')
        data = {}
        try:
            title = soup.title.text
            match = re.search(r'^(.+?)\(', title)
            data['Name'] = match.group(1).strip() if match else stock_id
        except: data['Name'] = stock_id

        def search_val(keyword):
            try:
                for item in soup.find_all('li'):
                    if keyword in item.text:
                        match = re.search(r'(-?\d+\.\d+|-?\d+)', item.text)
                        if match: return float(match.group(0))
            except: pass
            return None

        data['PE'] = search_val("æœ¬ç›Šæ¯”")
        data['PB'] = search_val("è‚¡åƒ¹æ·¨å€¼æ¯”")
        data['Yield'] = search_val("æ®–åˆ©ç‡")
        if data['Yield'] is None: data['Yield'] = search_val("ç¾é‡‘æ®–åˆ©ç‡")
        return data
    except: return {'Name': stock_id, 'PE': None, 'PB': None, 'Yield': None}

def get_financial_data(stock_id, info):
    """Yahoo åŸºç¤ä¼°å€¼æ•¸æ“š"""
    pe = info.get('trailingPE')
    pb = info.get('priceToBook')
    div_yield = info.get('dividendYield')
    if div_yield: div_yield = div_yield * 100

    if pe is None or pb is None or div_yield is None:
        web_data = get_yahoo_web_scraper(stock_id)
        if pe is None: pe = web_data.get('PE')
        if pb is None: pb = web_data.get('PB')
        if div_yield is None: div_yield = web_data.get('Yield')
        stock_name = web_data.get('Name', stock_id) if 'Name' in web_data else info.get('longName', stock_id)
    else:
        stock_name = info.get('longName', stock_id)
    return {"Name": stock_name, "PE": pe, "PB": pb, "Yield": div_yield}

def get_mops_insider(stock_id):
    clean_id = stock_id.replace(".TW", "").replace(".TWO", "")
    url = "https://mopsov.twse.com.tw/mops/web/ajax_t146sb05"
    now = datetime.datetime.now()
    for i in range(1, 4):
        try:
            check_date = now - datetime.timedelta(days=30 * i)
            year, month = check_date.year - 1911, check_date.month
            payload = {'encodeURIComponent': '1', 'step': '1', 'firstin': '1', 'off': '1', 'co_id': clean_id, 'year': str(year), 'month': str(month)}
            r = requests.post(url, data=payload, headers={'User-Agent': 'Mozilla/5.0'})
            dfs = pd.read_html(io.StringIO(r.text))
            for df in dfs:
                df.columns = df.columns.astype(str)
                if 'å…¨é«”è‘£ç›£äº‹æŒè‚¡åˆè¨ˆ' in df.to_string():
                    val = df.iloc[-1].astype(str).str.extract(r'(\d+\.?\d*)').dropna().iloc[-1, 0]
                    return float(val)
        except: continue
    return None

def get_chips_yahoo_api(stock_id):
    try:
        url = f"https://tw.stock.yahoo.com/_td-stock/api/resource/StockServices.3MajorTrade:K?symbol={stock_id}"
        r = requests.get(url, headers={"User-Agent": "Mozilla/5.0"})
        data = r.json()
        if 'data' in data and 'list' in data['data'] and len(data['data']['list']) > 0:
            latest = data['data']['list'][0]
            return {
                'foreign': int(latest.get('foreignDiff', 0)) // 1000,
                'trust': int(latest.get('investmentTrustDiff', 0)) // 1000,
                'dealer': int(latest.get('dealerDiff', 0)) // 1000
            }
    except: return None

# ==========================================
# ğŸ“Š æŠ€è¡“æŒ‡æ¨™
# ==========================================
def calculate_technicals(df):
    df['MA5'] = df['Close'].rolling(window=5).mean()
    df['MA20'] = df['Close'].rolling(window=20).mean()
    df['MA60'] = df['Close'].rolling(window=60).mean()
    exp1 = df['Close'].ewm(span=12, adjust=False).mean()
    exp2 = df['Close'].ewm(span=26, adjust=False).mean()
    df['MACD'] = exp1 - exp2
    df['Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()
    delta = df['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    df['RSI'] = 100 - (100 / (1 + rs))
    return df

# ==========================================
# ğŸ“ å ±å‘Šç”Ÿæˆå¼•æ“ (v10.0 Final)
# ==========================================
def generate_full_analysis(stock_id):
    stock = yf.Ticker(stock_id)
    df = stock.history(period="1y")
    if df.empty: return None
    
    info = stock.info
    df = calculate_technicals(df)
    today = df.iloc[-1]
    
    fin_data = get_financial_data(stock_id, info)
    chips = get_chips_yahoo_api(stock_id)
    insider = get_mops_insider(stock_id)
    
    # âœ… å¼·åˆ¶æŠ“å– Goodinfo (åŸºæœ¬é¢)
    adv_fin, fin_source_status = get_goodinfo_financials(stock_id)
    
    # âœ… å¼·åˆ¶æŠ“å– HiStock (ç±Œç¢¼é¢)
    histock_chip = get_histock_chips(stock_id)
    
    # è‹¥ Goodinfo å¾¹åº•å¤±æ•—ï¼Œè‡³å°‘çµ¦ç©ºå­—å…¸ä»¥å…å ±éŒ¯
    if not adv_fin: adv_fin = {}
    
    raw_summary = info.get('longBusinessSummary', '')
    zh_summary = translate_to_chinese(raw_summary)
    
    # --- è©•åˆ†ç³»çµ± ---
    score = 50
    reasons = []
    
    # æŠ€è¡“é¢
    if today['Close'] > today['MA20']: score += 10; reasons.append("è‚¡åƒ¹ç«™ä¸Šæœˆç·šï¼ŒçŸ­å¤šç¢ºç«‹")
    else: score -= 10; reasons.append("è‚¡åƒ¹è·Œç ´æœˆç·šï¼ŒçŸ­ç·šæ•´ç†")
    if today['Close'] > today['MA60']: score += 10; reasons.append("ç«™ç©©å­£ç·šï¼Œé•·å¤šæ ¼å±€")
    else: score -= 10
    
    # åŸºæœ¬é¢ (Goodinfo)
    if adv_fin.get('GrossMargin') and adv_fin['GrossMargin'] > 30:
        score += 5; reasons.append(f"æ¯›åˆ©ç‡é«˜ ({adv_fin['GrossMargin']:.1f}%)")
    if adv_fin.get('ROE') and adv_fin['ROE'] > 15:
        score += 5; reasons.append(f"ROE å„ªç•° ({adv_fin['ROE']:.1f}%)")
            
    # ç±Œç¢¼é¢
    chip_status = "æ•¸æ“šä¸è¶³"
    if chips:
        if chips['foreign'] > 0 and chips['trust'] > 0: score += 15; chip_status = "åœŸæ´‹åˆä¸€"; reasons.append("æ³•äººåŒæ­¥è²·è¶…")
        elif chips['foreign'] < 0 and chips['trust'] < 0: score -= 15; chip_status = "æ³•äººæ£„å®ˆ"; reasons.append("æ³•äººåŒæ­¥è³£è¶…")
        elif chips['trust'] > 0: score += 10; chip_status = "æŠ•ä¿¡èªé¤Š"
    
    if histock_chip:
        if histock_chip['big_change'] > 0: score += 10; reasons.append("å¤§æˆ¶æŒè‚¡å¢åŠ ")
        elif histock_chip['big_change'] < -0.2: score -= 10; reasons.append("å¤§æˆ¶æŒè‚¡é¬†å‹•")
            
    if insider and insider > 20: score += 5; reasons.append("è‘£ç›£æŒè‚¡é«˜")
    score = max(0, min(100, score))
    
    if score >= 75: verdict = "å¼·åŠ›è²·é€² (Strong Buy)"; color = "green"
    elif score >= 55: verdict = "æŒæœ‰/è§€æœ› (Hold)"; color = "orange"
    else: verdict = "è³£å‡º/é¿é–‹ (Sell)"; color = "red"
    
    # --- æœªä¾†å±•æœ› (é‚è¼¯ç”Ÿæˆ) ---
    outlook_text = {"catalysts": [], "risks": [], "thesis": ""}
    
    # å‚¬åŒ–åŠ‘
    if histock_chip and histock_chip['big_change'] > 0: outlook_text["catalysts"].append(f"**ç±Œç¢¼æ²‰æ¾±**ï¼šå¤§æˆ¶æŒè‚¡æœ¬é€±å¢åŠ  {histock_chip['big_change']:.2f}%ï¼Œä¸»åŠ›å¸ç±Œæ˜é¡¯ã€‚")
    if adv_fin.get('GrossMargin', 0) > 40: outlook_text["catalysts"].append(f"**è­·åŸæ²³å„ªå‹¢**ï¼šæ¯›åˆ©ç‡é” {adv_fin['GrossMargin']:.1f}%ï¼Œé¡¯ç¤ºç”¢å“å…·å‚™å¼·å¤§å®šåƒ¹æ¬Šã€‚")
    if chips and chips['trust'] > 0: outlook_text["catalysts"].append("**æŠ•ä¿¡ä½œå¸³**ï¼šæŠ•ä¿¡è¿‘æœŸè²·è¶…ï¼Œå­£åº•ä½œå¸³è¡Œæƒ…å¯æœŸã€‚")
    if today['Close'] > today['MA60']: outlook_text["catalysts"].append("**å¤šé ­æ¶æ§‹**ï¼šè‚¡åƒ¹ä½æ–¼å­£ç·šä¹‹ä¸Šï¼Œé•·ç·šè¶¨å‹¢åå¤šã€‚")
    if not outlook_text["catalysts"]: outlook_text["catalysts"].append("**å€é–“éœ‡ç›ª**ï¼šç›®å‰ç¼ºä¹æ˜ç¢ºæ”»æ“Šè¨Šè™Ÿï¼Œç­‰å¾…é‡èƒ½æ”¾å¤§ã€‚")

    # é¢¨éšª
    if today['RSI'] > 75: outlook_text["risks"].append("**æŒ‡æ¨™éç†±**ï¼šRSI æŒ‡æ¨™éé«˜ï¼ŒçŸ­ç·šå¯èƒ½ä¿®æ­£ã€‚")
    if fin_data['PE'] and float(fin_data['PE']) > 35: outlook_text["risks"].append("**ä¼°å€¼åé«˜**ï¼šæœ¬ç›Šæ¯”é«˜æ–¼å¸‚å ´å¹³å‡ï¼Œéœ€ç•™æ„ä¿®æ­£é¢¨éšªã€‚")
    if not outlook_text["risks"]: outlook_text["risks"].append("**ç³»çµ±é¢¨éšª**ï¼šç•™æ„å¤§ç›¤æ³¢å‹•ã€‚")
    
    thesis_fin = 'ç²åˆ©èƒ½åŠ›å¼·å‹' if adv_fin.get('ROE',0) > 10 else 'ç²åˆ©å¹³ç©©'
    if not adv_fin: thesis_fin = "è²¡å‹™æ•¸æ“šå¾…ç¢ºèª"
    
    outlook_text["thesis"] = f"ç¶œåˆåˆ†æï¼Œ{fin_data['Name']} è©•åˆ†ç‚º **{score} åˆ†**ã€‚åŸºæœ¬é¢é¡¯ç¤º{thesis_fin}ã€‚å»ºè­°é—œæ³¨ **{verdict.split('(')[0]}**ã€‚"

    return {
        "id": stock_id, "name": fin_data['Name'], "price": today['Close'], "score": score,
        "verdict": verdict, "color": color, "reasons": reasons,
        "fin": fin_data, "chips": chips, "chip_status": chip_status,
        "insider": insider, 
        "histock_chip": histock_chip, 
        "adv_fin": adv_fin,
        "fin_source_status": fin_source_status,
        "today": today, "info": info, "zh_summary": zh_summary,
        "outlook": outlook_text
    }

# ==========================================
# ğŸ–¥ï¸ UI ä»‹é¢
# ==========================================
st.title("å¸¥å“¥åŸ AI æŠ•é¡§")
st.markdown("### ğŸš€ æ©Ÿæ§‹ç´šæŠ•è³‡åˆ†æå ±å‘Šæ›¸")

col1, col2 = st.columns([3, 1])
with col1:
    user_input = st.text_input("è¼¸å…¥ä»£ç¢¼ (ä¾‹å¦‚ 2330, 2603)", "")
with col2:
    st.write("")
    st.write("")
    run_btn = st.button("ç”Ÿæˆå ±å‘Š", use_container_width=True)

if run_btn and user_input:
    stock_code = user_input.strip().upper()
    if stock_code.isdigit(): stock_code += ".TW"
    
    with st.spinner("æŸ¥è©¢ä¸­..."):
        data = generate_full_analysis(stock_code)
        
    if data:
        st.header(f"1. åŸ·è¡Œæ‘˜è¦ï¼š{data['name']} ({stock_code})")
        m1, m2, m3, m4 = st.columns(4)
        m1.metric("ç¶œåˆä¿¡å¿µè©•åˆ†", f"{data['score']} / 100")
        m2.metric("æŠ•è³‡å»ºè­°", data['verdict'].split(' ')[0])
        m3.metric("æœ€æ–°æ”¶ç›¤åƒ¹", f"{data['price']:.2f}")
        m4.caption(f"ä¾†æºç‹€æ…‹ï¼š{data['fin_source_status']}")
        
        st.info(f"ç³»çµ±å»ºè­°ï¼š**{data['verdict'].split('(')[0]}**ã€‚é—œéµå› ç´ ï¼š**{data['reasons'][0] if data['reasons'] else 'ä¸­æ€§'}**ã€‚")

        tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ¢ å•†æ¥­èˆ‡åŸºæœ¬é¢", "ğŸ’° è²¡å‹™èˆ‡ä¼°å€¼", "ğŸ¦ è‚¡æ¬Šèˆ‡ç±Œç¢¼", "ğŸ“ˆ æŠ€è¡“åˆ†æ", "âš–ï¸ æœªä¾†å±•æœ›èˆ‡æˆ°ç•¥"])
        
        with tab1:
            st.subheader("æ¥­å‹™èƒŒæ™¯")
            st.write(data['zh_summary'])
            st.markdown("---")
            st.caption(f"ç”¢æ¥­ï¼š{data['info'].get('sector', 'N/A')} > {data['info'].get('industry', 'N/A')}")
            
        with tab2:
            st.subheader("è²¡å‹™ç¸¾æ•ˆ (Financials)")
            
            f1, f2, f3 = st.columns(3)
            pe = f"{data['fin']['PE']:.2f}" if data['fin']['PE'] else "N/A"
            pb = f"{data['fin']['PB']:.2f}" if data['fin']['PB'] else "N/A"
            yld = f"{data['fin']['Yield']:.2f}%" if data['fin']['Yield'] else "N/A"
            f1.metric("æœ¬ç›Šæ¯” (P/E)", pe); f2.metric("è‚¡åƒ¹æ·¨å€¼æ¯” (P/B)", pb); f3.metric("æ®–åˆ©ç‡", yld)

            st.divider()
            
            st.markdown(f"#### ğŸ“Š ç²åˆ©èƒ½åŠ›èˆ‡ç¶“ç‡Ÿç¸¾æ•ˆ (Goodinfo)")
            if data['adv_fin']:
                gf = data['adv_fin']
                g1, g2, g3, g4 = st.columns(4)
                
                def fmt(v, suffix='%'): return f"{v:.2f}{suffix}" if v is not None else "N/A"
                
                g1.metric("æ¯›åˆ©ç‡", fmt(gf.get('GrossMargin')), help="è¶Šé«˜è¶Šå¥½")
                g2.metric("ç‡Ÿæ¥­åˆ©ç›Šç‡", fmt(gf.get('OpMargin')))
                g3.metric("ç¨…å¾Œæ·¨åˆ©ç‡", fmt(gf.get('NetMargin')))
                g4.metric("ROE (æ¬Šç›Šå ±é…¬)", fmt(gf.get('ROE')))
                
                st.write("")
                
                g5, g6, g7, g8 = st.columns(4)
                g5.metric("EPS (æ¯è‚¡ç›ˆé¤˜)", fmt(gf.get('EPS'), ' å…ƒ'))
                g6.metric("æ¯è‚¡æ·¨å€¼ (BPS)", fmt(gf.get('BPS'), ' å…ƒ'))
                g7.metric("ROA (è³‡ç”¢å ±é…¬)", fmt(gf.get('ROA')))
                g8.caption(f"æ•¸æ“šä¾†æºï¼š{data['fin_source_status']}")
            else:
                st.warning(f"âš ï¸ ç„¡æ³•å–å¾— Goodinfo æ•¸æ“šï¼Œç‹€æ…‹ï¼š{data['fin_source_status']}")

        with tab3:
            st.subheader("æ‰€æœ‰æ¬Šèˆ‡äº¤æ˜“å‹•æ…‹")
            
            st.markdown("#### ğŸ“Š é›†ä¿åˆ†ä½ˆ (HiStock å—¨æŠ•è³‡)")
            if data['histock_chip']:
                hc = data['histock_chip']
                g1, g2, g3 = st.columns(3)
                g1.metric("400å¼µä»¥ä¸Šå¤§æˆ¶", f"{hc['big_percent']}%", f"{hc['big_change']:.2f}%")
                g2.metric("è‚¡æ±äººæ•¸", f"{hc['holders']} äºº", f"{hc['holders_change']} äºº", delta_color="inverse")
                g3.caption(f"çµ±è¨ˆæ—¥æœŸï¼š{hc['date']}")
                if hc['big_change'] > 0: st.success("ğŸ”¥ ç±Œç¢¼é›†ä¸­ (å¤§æˆ¶è²·)")
                elif hc['big_change'] < 0: st.error("âš ï¸ ç±Œç¢¼é¬†å‹• (å¤§æˆ¶è³£)")
            else:
                st.warning("âš ï¸ å—¨æŠ•è³‡çˆ¬èŸ²æœªæŠ“å–åˆ°è¡¨æ ¼ï¼Œå¯èƒ½ç¶²é çµæ§‹æ”¹è®Šã€‚")
            
            st.divider()
            c1, c2 = st.columns(2)
            with c1:
                st.markdown("#### ğŸ›ï¸ ä¸‰å¤§æ³•äºº")
                if data['chips']: st.json(data['chips'])
            with c2:
                st.markdown("#### ğŸ‘” å…§éƒ¨äººæŒè‚¡")
                if data['insider']: st.metric("è‘£ç›£æŒè‚¡", f"{data['insider']}%")

        with tab4:
            st.subheader("æŠ€è¡“åˆ†æ")
            t1, t2, t3 = st.columns(3)
            t1.metric("RSI (14)", f"{data['today']['RSI']:.2f}")
            t2.metric("MACD", f"{data['today']['MACD'] - data['today']['Signal']:.2f}")
            t3.metric("æœˆç·šä¹–é›¢", f"{data['price'] - data['today']['MA20']:.2f}")

        with tab5:
            st.subheader("æœªä¾†å±•æœ›èˆ‡æˆ°ç•¥å‚¬åŒ–åŠ‘")
            st.markdown(f"**åˆ†ææ—¥æœŸ**ï¼š{datetime.date.today()}")
            st.markdown("#### 1. æˆ°ç•¥å‚¬åŒ–åŠ‘")
            for i in data['outlook']['catalysts']: st.markdown(f"- {i}")
            st.markdown("#### 2. é¢¨éšªçŸ©é™£")
            for i in data['outlook']['risks']: st.markdown(f"- âš ï¸ {i}")
            st.markdown("#### 3. ç¶œåˆæŠ•è³‡è«–è¿°")
            st.info(data['outlook']['thesis'])
            st.caption("*(å…è²¬è²æ˜ï¼šæœ¬å ±å‘Šç”± AI è‡ªå‹•ç”Ÿæˆï¼Œåƒ…ä¾›åƒè€ƒ)*")

    else:
        st.error(f"âŒ æŸ¥ç„¡ä»£ç¢¼ {stock_code}")
