import streamlit as st
import yfinance as yf
import requests
import pandas as pd
import datetime
import io
import re
from bs4 import BeautifulSoup
from deep_translator import GoogleTranslator

# ==========================================
# âš™ï¸ ç¶²é è¨­å®š
# ==========================================
st.set_page_config(page_title="å¸¥å“¥åŸ AI æŠ•é¡§", page_icon="ğŸ“ˆ", layout="wide")

# å»ºç«‹ Session ç¶­æŒé€£ç·š
session = requests.Session()
session.headers.update({
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
})

# ==========================================
# ğŸ› ï¸ å·¥å…·å‡½å¼
# ==========================================
def translate_to_chinese(text):
    try:
        if not text or len(text) < 5: return "æš«ç„¡è©³ç´°æ¥­å‹™æè¿°ã€‚"
        return GoogleTranslator(source='auto', target='zh-TW').translate(text)
    except: return text

# ==========================================
# ğŸ•µï¸â€â™‚ï¸ æ•¸æ“šç²å–å±¤ (FinMind + Yahoo)
# ==========================================

def get_finmind_equity(stock_id):
    """
    [æ–°å¢] ä½¿ç”¨ FinMind API æŠ“å–é›†ä¿åˆ†ä½ˆ
    å„ªé»ï¼šå®˜æ–¹ APIï¼Œç©©å®šä¸è¢«é–
    å…§å®¹ï¼š400å¼µä»¥ä¸Šå¤§æˆ¶æ¯”ä¾‹ã€ç¸½è‚¡æ±äººæ•¸
    """
    clean_id = stock_id.replace(".TW", "").replace(".TWO", "")
    
    # è¨­å®šæŠ“å–éå» 90 å¤©è³‡æ–™ï¼Œç¢ºä¿èƒ½è·¨é€±æ¯”è¼ƒ
    start_date = (datetime.datetime.now() - datetime.timedelta(days=90)).strftime('%Y-%m-%d')
    
    url = "https://api.finmindtrade.com/api/v4/data"
    parameter = {
        "dataset": "TaiwanStockHoldingSharesPer",
        "data_id": clean_id,
        "start_date": start_date
    }
    
    try:
        r = requests.get(url, params=parameter, timeout=10)
        data = r.json().get('data', [])
        
        if not data: return None
        
        df = pd.DataFrame(data)
        df['date'] = pd.to_datetime(df['date'])
        
        # å–å¾—æ‰€æœ‰å¯ç”¨æ—¥æœŸ
        dates = sorted(df['date'].unique())
        if len(dates) < 2: return None 
        
        # å–æœ€è¿‘å…©æœŸ (æœ¬é€± vs ä¸Šé€±)
        latest_date = dates[-1]
        prev_date = dates[-2]
        
        df_latest = df[df['date'] == latest_date]
        df_prev = df[df['date'] == prev_date]
        
        # è¨ˆç®—ç¸½è‚¡æ±äººæ•¸
        holders_now = df_latest['numberOfShareholders'].sum()
        holders_prev = df_prev['numberOfShareholders'].sum()
        
        # è¨ˆç®— 400 å¼µä»¥ä¸Šå¤§æˆ¶æ¯”ä¾‹
        # FinMind ç­‰ç´š 16 å°æ‡‰ 400,001-600,000 è‚¡
        # æˆ‘å€‘åŠ ç¸½ç­‰ç´š >= 16 çš„æ¯”ä¾‹ (åš´æ ¼å®šç¾© > 400å¼µ)
        def calc_big_percent(dframe):
            dframe['HoldingSharesLevel'] = pd.to_numeric(dframe['HoldingSharesLevel'], errors='coerce')
            # 16ç´šä»¥ä¸Šæ˜¯å¤§æˆ¶
            big_df = dframe[dframe['HoldingSharesLevel'] >= 16]
            return big_df['percentage'].sum()
            
        big_now = calc_big_percent(df_latest)
        big_prev = calc_big_percent(df_prev)
        
        return {
            "source": "FinMind API",
            "date": latest_date.strftime('%Y-%m-%d'),
            "big_percent": big_now,
            "big_change": big_now - big_prev,
            "holders": int(holders_now),
            "holders_change": int(holders_now) - int(holders_prev)
        }
        
    except Exception as e:
        print(f"FinMind Error: {e}")
        return None

def get_yahoo_financial_ratios(stock_id):
    """Yahoo è²¡å‹™æ¯”ç‡çˆ¬èŸ² (ç©©å®šç‰ˆ)"""
    try:
        url = f"https://tw.stock.yahoo.com/quote/{stock_id}/financial-ratios"
        r = session.get(url, timeout=5)
        soup = BeautifulSoup(r.text, 'html.parser')
        text_content = soup.get_text()
        
        data = {}
        def extract_percent(keyword):
            pattern = re.compile(f"{keyword}.*?(-?\d+\.?\d+)%")
            match = pattern.search(text_content)
            return float(match.group(1)) if match else None

        data['GrossMargin'] = extract_percent("æ¯›åˆ©ç‡")
        data['OpMargin'] = extract_percent("ç‡Ÿæ¥­åˆ©ç›Šç‡")
        data['NetMargin'] = extract_percent("ç¨…å¾Œæ·¨åˆ©ç‡")
        data['ROE'] = extract_percent("è‚¡æ±æ¬Šç›Šå ±é…¬ç‡")
        data['ROA'] = extract_percent("è³‡ç”¢å ±é…¬ç‡")
        
        def extract_val(keyword):
            pattern = re.compile(f"{keyword}.*?(-?\d+\.?\d+)")
            match = pattern.search(text_content)
            return float(match.group(1)) if match else None
            
        data['EPS'] = extract_val("æ¯è‚¡ç›ˆé¤˜")
        data['BPS'] = extract_val("æ¯è‚¡æ·¨å€¼")
        
        return data
    except: return {}

def get_yahoo_web_scraper(stock_id):
    try:
        url = f"https://tw.stock.yahoo.com/quote/{stock_id}"
        r = session.get(url, timeout=5)
        soup = BeautifulSoup(r.text, 'html.parser')
        data = {}
        try:
            title = soup.title.text
            match = re.search(r'^(.+?)\(', title)
            data['Name'] = match.group(1).strip() if match else stock_id
        except: data['Name'] = stock_id

        def search_val(keyword):
            try:
                for item in soup.find_all('li'):
                    if keyword in item.text:
                        match = re.search(r'(-?\d+\.\d+|-?\d+)', item.text)
                        if match: return float(match.group(0))
            except: pass
            return None

        data['PE'] = search_val("æœ¬ç›Šæ¯”")
        data['PB'] = search_val("è‚¡åƒ¹æ·¨å€¼æ¯”")
        data['Yield'] = search_val("æ®–åˆ©ç‡")
        if data['Yield'] is None: data['Yield'] = search_val("ç¾é‡‘æ®–åˆ©ç‡")
        return data
    except: return {'Name': stock_id, 'PE': None, 'PB': None, 'Yield': None}

def get_financial_data(stock_id, info):
    pe = info.get('trailingPE')
    pb = info.get('priceToBook')
    div_yield = info.get('dividendYield')
    if div_yield: div_yield = div_yield * 100

    if pe is None or pb is None or div_yield is None:
        web_data = get_yahoo_web_scraper(stock_id)
        if pe is None: pe = web_data.get('PE')
        if pb is None: pb = web_data.get('PB')
        if div_yield is None: div_yield = web_data.get('Yield')
        stock_name = web_data.get('Name', stock_id) if 'Name' in web_data else info.get('longName', stock_id)
    else:
        stock_name = info.get('longName', stock_id)
    return {"Name": stock_name, "PE": pe, "PB": pb, "Yield": div_yield}

def get_mops_insider(stock_id):
    clean_id = stock_id.replace(".TW", "").replace(".TWO", "")
    url = "https://mopsov.twse.com.tw/mops/web/ajax_t146sb05"
    now = datetime.datetime.now()
    for i in range(1, 4):
        try:
            check_date = now - datetime.timedelta(days=30 * i)
            year, month = check_date.year - 1911, check_date.month
            payload = {'encodeURIComponent': '1', 'step': '1', 'firstin': '1', 'off': '1', 'co_id': clean_id, 'year': str(year), 'month': str(month)}
            r = requests.post(url, data=payload, headers={'User-Agent': 'Mozilla/5.0'})
            dfs = pd.read_html(io.StringIO(r.text))
            for df in dfs:
                df.columns = df.columns.astype(str)
                if 'å…¨é«”è‘£ç›£äº‹æŒè‚¡åˆè¨ˆ' in df.to_string():
                    val = df.iloc[-1].astype(str).str.extract(r'(\d+\.?\d*)').dropna().iloc[-1, 0]
                    return float(val)
        except: continue
    return None

def get_chips_yahoo_api(stock_id):
    try:
        url = f"https://tw.stock.yahoo.com/_td-stock/api/resource/StockServices.3MajorTrade:K?symbol={stock_id}"
        r = requests.get(url, headers={"User-Agent": "Mozilla/5.0"})
        data = r.json()
        if 'data' in data and 'list' in data['data'] and len(data['data']['list']) > 0:
            latest = data['data']['list'][0]
            return {
                'foreign': int(latest.get('foreignDiff', 0)) // 1000,
                'trust': int(latest.get('investmentTrustDiff', 0)) // 1000,
                'dealer': int(latest.get('dealerDiff', 0)) // 1000
            }
    except: return None

# ==========================================
# ğŸ“Š æŠ€è¡“æŒ‡æ¨™
# ==========================================
def calculate_technicals(df):
    df['MA5'] = df['Close'].rolling(window=5).mean()
    df['MA20'] = df['Close'].rolling(window=20).mean()
    df['MA60'] = df['Close'].rolling(window=60).mean()
    exp1 = df['Close'].ewm(span=12, adjust=False).mean()
    exp2 = df['Close'].ewm(span=26, adjust=False).mean()
    df['MACD'] = exp1 - exp2
    df['Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()
    delta = df['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    df['RSI'] = 100 - (100 / (1 + rs))
    return df

# ==========================================
# ğŸ“ å ±å‘Šç”Ÿæˆå¼•æ“ (v12.0 Final)
# ==========================================
def generate_full_analysis(stock_id):
    stock = yf.Ticker(stock_id)
    df = stock.history(period="1y")
    if df.empty: return None
    
    info = stock.info
    df = calculate_technicals(df)
    today = df.iloc[-1]
    
    fin_data = get_financial_data(stock_id, info)
    chips = get_chips_yahoo_api(stock_id)
    insider = get_mops_insider(stock_id)
    
    # âœ… 1. FinMind API æŠ“ç±Œç¢¼
    finmind_chip = get_finmind_equity(stock_id)
    
    # âœ… 2. Yahoo è²¡å‹™æ¯”ç‡çˆ¬èŸ²
    adv_fin = get_yahoo_financial_ratios(stock_id)
    
    # è£œå¼·è²¡å‹™æ•¸æ“š
    if not adv_fin.get('GrossMargin'):
        def pct(v): return v*100 if v else None
        adv_fin = {
            'GrossMargin': pct(info.get('grossMargins')),
            'OpMargin': pct(info.get('operatingMargins')),
            'NetMargin': pct(info.get('profitMargins')),
            'ROE': pct(info.get('returnOnEquity')),
            'ROA': pct(info.get('returnOnAssets')),
            'EPS': info.get('trailingEps'),
            'BPS': info.get('bookValue')
        }
        fin_source = "yfinance (API)"
    else:
        fin_source = "Yahoo è‚¡å¸‚ (Crawler)"

    raw_summary = info.get('longBusinessSummary', '')
    zh_summary = translate_to_chinese(raw_summary)
    
    # --- è©•åˆ† ---
    score = 50
    reasons = []
    
    if today['Close'] > today['MA20']: score += 10; reasons.append("è‚¡åƒ¹ç«™ä¸Šæœˆç·šï¼ŒçŸ­å¤šç¢ºç«‹")
