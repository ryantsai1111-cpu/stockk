import streamlit as st
import yfinance as yf
import requests
import pandas as pd
import datetime
import io
import re
from bs4 import BeautifulSoup
from deep_translator import GoogleTranslator

# ==========================================
# âš™ï¸ ç¶²é è¨­å®š
# ==========================================
st.set_page_config(page_title="å¸¥å“¥åŸ AI æŠ•é¡§", page_icon="ğŸ“ˆ", layout="wide")

# ==========================================
# ğŸ› ï¸ å·¥å…·å‡½å¼
# ==========================================
def translate_to_chinese(text):
    try:
        if not text or len(text) < 5: return "æš«ç„¡è©³ç´°æ¥­å‹™æè¿°ã€‚"
        return GoogleTranslator(source='auto', target='zh-TW').translate(text)
    except: return text

# å»ºç«‹ Session ç¶­æŒé€£ç·š
session = requests.Session()
session.headers.update({
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
})

# ==========================================
# ğŸ•µï¸â€â™‚ï¸ æ•¸æ“šç²å–å±¤ (Yahoo å…¨é¢æ¥ç®¡)
# ==========================================

def get_yahoo_financial_ratios(stock_id):
    """
    [æ–°å¢] çˆ¬å– Yahoo è‚¡å¸‚ 'è²¡å‹™æ¯”ç‡' é é¢
    æ›¿ä»£ Goodinfoï¼ŒæŠ“å–ç²åˆ©èƒ½åŠ›æ•¸æ“š (ä¸æ˜“è¢«å°é–)
    """
    try:
        url = f"https://tw.stock.yahoo.com/quote/{stock_id}/financial-ratios"
        r = session.get(url, timeout=5)
        soup = BeautifulSoup(r.text, 'html.parser')
        
        data = {}
        
        # Yahoo çš„æ•¸æ“šé€šå¸¸åœ¨ li åˆ—è¡¨å…§ï¼Œæ ¼å¼ç‚º "æ¯›åˆ©ç‡ 25.4%"
        # æˆ‘å€‘éæ­·æ‰€æœ‰æ–‡å­—å…§å®¹ä¾†æŠ“å–
        text_content = soup.get_text()
        
        def extract_percent(keyword):
            # å°‹æ‰¾ "æ¯›åˆ©ç‡" å¾Œé¢çš„æ•¸å­—
            # æ¨¡å¼ï¼šé—œéµå­— -> å¯èƒ½æœ‰ç©ºæ ¼/å†’è™Ÿ -> æ•¸å­— -> %
            pattern = re.compile(f"{keyword}.*?(-?\d+\.?\d+)%")
            match = pattern.search(text_content)
            return float(match.group(1)) if match else None

        data['GrossMargin'] = extract_percent("æ¯›åˆ©ç‡")
        data['OpMargin'] = extract_percent("ç‡Ÿæ¥­åˆ©ç›Šç‡")
        data['NetMargin'] = extract_percent("ç¨…å¾Œæ·¨åˆ©ç‡")
        data['ROE'] = extract_percent("è‚¡æ±æ¬Šç›Šå ±é…¬ç‡")
        data['ROA'] = extract_percent("è³‡ç”¢å ±é…¬ç‡")
        
        # æŠ“å–æ¯è‚¡ç›ˆé¤˜ (EPS) å’Œ æ¯è‚¡æ·¨å€¼ (BPS)
        # é€™äº›é€šå¸¸åœ¨ "åŸºæœ¬è³‡æ–™" æˆ– "è²¡å‹™æ¯”ç‡" çš„å…¶ä»–å€å¡Šï¼Œæˆ‘å€‘å˜—è©¦ç”¨ Regex æš´åŠ›æœ
        def extract_val(keyword):
            pattern = re.compile(f"{keyword}.*?(-?\d+\.?\d+)")
            match = pattern.search(text_content)
            return float(match.group(1)) if match else None
            
        data['EPS'] = extract_val("æ¯è‚¡ç›ˆé¤˜")
        data['BPS'] = extract_val("æ¯è‚¡æ·¨å€¼")
        
        return data
    except Exception as e:
        print(f"Yahoo Scraper Error: {e}")
        return {}

def get_histock_chips(stock_id):
    """[ç±Œç¢¼é¢] å¾ HiStock æŠ“å–é›†ä¿åˆ†ä½ˆ"""
    clean_id = stock_id.replace(".TW", "").replace(".TWO", "")
    url = f"https://histock.tw/stock/large.aspx?no={clean_id}"
    try:
        r = session.get(url, timeout=10)
        soup = BeautifulSoup(r.text, 'html.parser')
        tables = soup.find_all('table')
        target_table = None
        for t in tables:
            if "400å¼µ" in t.text and "è‚¡æ±äººæ•¸" in t.text:
                target_table = t
                break
        
        if target_table:
            rows = target_table.find_all('tr')
            if len(rows) >= 3:
                row_now = rows[1].find_all('td')
                row_prev = rows[2].find_all('td')
                headers = [th.text.strip() for th in rows[0].find_all('th')]
                if not headers: headers = [td.text.strip() for td in rows[0].find_all('td')]
                
                idx_big = -1; idx_holders = -1; idx_date = 0
                for i, h in enumerate(headers):
                    if "400å¼µ" in h and "%" in h: idx_big = i
                    if "äººæ•¸" in h: idx_holders = i
                    if "æœŸ" in h or "å‘¨" in h or "æ—¥" in h: idx_date = i
                
                if idx_big != -1 and idx_holders != -1:
                    curr_big = float(row_now[idx_big].text.replace('%', '').strip())
                    prev_big = float(row_prev[idx_big].text.replace('%', '').strip())
                    curr_hold = int(row_now[idx_holders].text.replace(',', '').strip())
                    prev_hold = int(row_prev[idx_holders].text.replace(',', '').strip())
                    date_str = row_now[idx_date].text.strip()
                    
                    return {
                        "source": "HiStock",
                        "date": date_str,
                        "big_percent": curr_big,
                        "big_change": curr_big - prev_big,
                        "holders": curr_hold,
                        "holders_change": curr_hold - prev_hold
                    }
    except: return None
    return None

def get_yahoo_basic_scraper(stock_id):
    """æŠ“å–åŸºæœ¬ä¼°å€¼ (æœ¬ç›Šæ¯”/æ®–åˆ©ç‡)"""
    try:
        url = f"https://tw.stock.yahoo.com/quote/{stock_id}"
        r = session.get(url, timeout=5)
        soup = BeautifulSoup(r.text, 'html.parser')
        data = {}
        try:
            title = soup.title.text
            match = re.search(r'^(.+?)\(', title)
            data['Name'] = match.group(1).strip() if match else stock_id
        except: data['Name'] = stock_id

        def search_val(keyword):
            try:
                for item in soup.find_all('li'):
                    if keyword in item.text:
                        match = re.search(r'(-?\d+\.\d+|-?\d+)', item.text)
                        if match: return float(match.group(0))
            except: pass
            return None

        data['PE'] = search_val("æœ¬ç›Šæ¯”")
        data['PB'] = search_val("è‚¡åƒ¹æ·¨å€¼æ¯”")
        data['Yield'] = search_val("æ®–åˆ©ç‡")
        if data['Yield'] is None: data['Yield'] = search_val("ç¾é‡‘æ®–åˆ©ç‡")
        return data
    except: return {'Name': stock_id, 'PE': None, 'PB': None, 'Yield': None}

def get_financial_data(stock_id, info):
    pe = info.get('trailingPE')
    pb = info.get('priceToBook')
    div_yield = info.get('dividendYield')
    if div_yield: div_yield = div_yield * 100

    if pe is None or pb is None or div_yield is None:
        web_data = get_yahoo_basic_scraper(stock_id)
        if pe is None: pe = web_data.get('PE')
        if pb is None: pb = web_data.get('PB')
        if div_yield is None: div_yield = web_data.get('Yield')
        stock_name = web_data.get('Name', stock_id) if 'Name' in web_data else info.get('longName', stock_id)
    else:
        stock_name = info.get('longName', stock_id)
    return {"Name": stock_name, "PE": pe, "PB": pb, "Yield": div_yield}

def get_mops_insider(stock_id):
    clean_id = stock_id.replace(".TW", "").replace(".TWO", "")
    url = "https://mopsov.twse.com.tw/mops/web/ajax_t146sb05"
    now = datetime.datetime.now()
    for i in range(1, 4):
        try:
            check_date = now - datetime.timedelta(days=30 * i)
            year, month = check_date.year - 1911, check_date.month
            payload = {'encodeURIComponent': '1', 'step': '1', 'firstin': '1', 'off': '1', 'co_id': clean_id, 'year': str(year), 'month': str(month)}
            r = requests.post(url, data=payload, headers={'User-Agent': 'Mozilla/5.0'})
            dfs = pd.read_html(io.StringIO(r.text))
            for df in dfs:
                df.columns = df.columns.astype(str)
                if 'å…¨é«”è‘£ç›£äº‹æŒè‚¡åˆè¨ˆ' in df.to_string():
                    val = df.iloc[-1].astype(str).str.extract(r'(\d+\.?\d*)').dropna().iloc[-1, 0]
                    return float(val)
        except: continue
    return None

def get_chips_yahoo_api(stock_id):
    try:
        url = f"https://tw.stock.yahoo.com/_td-stock/api/resource/StockServices.3MajorTrade:K?symbol={stock_id}"
        r = requests.get(url, headers={"User-Agent": "Mozilla/5.0"})
        data = r.json()
        if 'data' in data and 'list' in data['data'] and len(data['data']['list']) > 0:
            latest = data['data']['list'][0]
            return {
                'foreign': int(latest.get('foreignDiff', 0)) // 1000,
                'trust': int(latest.get('investmentTrustDiff', 0)) // 1000,
                'dealer': int(latest.get('dealerDiff', 0)) // 1000
            }
    except: return None

# ==========================================
# ğŸ“Š æŠ€è¡“æŒ‡æ¨™
# ==========================================
def calculate_technicals(df):
    df['MA5'] = df['Close'].rolling(window=5).mean()
    df['MA20'] = df['Close'].rolling(window=20).mean()
    df['MA60'] = df['Close'].rolling(window=60).mean()
    exp1 = df['Close'].ewm(span=12, adjust=False).mean()
    exp2 = df['Close'].ewm(span=26, adjust=False).mean()
    df['MACD'] = exp1 - exp2
    df['Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()
    delta = df['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    df['RSI'] = 100 - (100 / (1 + rs))
    return df

# ==========================================
# ğŸ“ å ±å‘Šç”Ÿæˆå¼•æ“ (v11.0 Yahoo Financials)
# ==========================================
def generate_full_analysis(stock_id):
    stock = yf.Ticker(stock_id)
    df = stock.history(period="1y")
    if df.empty: return None
    
    info = stock.info
    df = calculate_technicals(df)
    today = df.iloc[-1]
    
    fin_data = get_financial_data(stock_id, info)
    chips = get_chips_yahoo_api(stock_id)
    insider = get_mops_insider(stock_id)
    histock_chip = get_histock_chips(stock_id)
    
    # âœ… æ”¹ç”¨ Yahoo è²¡å‹™æ¯”ç‡çˆ¬èŸ² (ç©©å®šä¸å°é–)
    adv_fin = get_yahoo_financial_ratios(stock_id)
    
    # å¦‚æœçˆ¬èŸ²å¤±æ•—ï¼Œå˜—è©¦ç”¨ yfinance info è£œæ•‘
    if not adv_fin.get('GrossMargin'):
        def pct(v): return v*100 if v else None
        adv_fin = {
            'GrossMargin': pct(info.get('grossMargins')),
            'OpMargin': pct(info.get('operatingMargins')),
            'NetMargin': pct(info.get('profitMargins')),
            'ROE': pct(info.get('returnOnEquity')),
            'ROA': pct(info.get('returnOnAssets')),
            'EPS': info.get('trailingEps'),
            'BPS': info.get('bookValue')
        }
        fin_source = "yfinance (API)"
    else:
        fin_source = "Yahoo è‚¡å¸‚ (Crawler)"

    raw_summary = info.get('longBusinessSummary', '')
    zh_summary = translate_to_chinese(raw_summary)
    
    # --- è©•åˆ†ç³»çµ± ---
    score = 50
    reasons = []
    
    # æŠ€è¡“é¢
    if today['Close'] > today['MA20']: score += 10; reasons.append("è‚¡åƒ¹ç«™ä¸Šæœˆç·šï¼ŒçŸ­å¤šç¢ºç«‹")
    else: score -= 10; reasons.append("è‚¡åƒ¹è·Œç ´æœˆç·šï¼ŒçŸ­ç·šæ•´ç†")
    if today['Close'] > today['MA60']: score += 10; reasons.append("ç«™ç©©å­£ç·šï¼Œé•·å¤šæ ¼å±€")
    else: score -= 10
    
    # åŸºæœ¬é¢ (Yahoo Adv)
    if adv_fin.get('GrossMargin') and adv_fin['GrossMargin'] > 30:
        score += 5; reasons.append(f"æ¯›åˆ©ç‡é«˜ ({adv_fin['GrossMargin']:.1f}%)")
    if adv_fin.get('ROE') and adv_fin['ROE'] > 15:
        score += 5; reasons.append(f"ROE å„ªç•° ({adv_fin['ROE']:.1f}%)")
            
    # ç±Œç¢¼é¢
    chip_status = "æ•¸æ“šä¸è¶³"
    if chips:
        if chips['foreign'] > 0 and chips['trust'] > 0: score += 15; chip_status = "åœŸæ´‹åˆä¸€"; reasons.append("æ³•äººåŒæ­¥è²·è¶…")
        elif chips['foreign'] < 0 and chips['trust'] < 0: score -= 15; chip_status = "æ³•äººæ£„å®ˆ"; reasons.append("æ³•äººåŒæ­¥è³£è¶…")
        elif chips['trust'] > 0: score += 10; chip_status = "æŠ•ä¿¡èªé¤Š"
    
    if histock_chip:
        if histock_chip['big_change'] > 0: score += 10; reasons.append("å¤§æˆ¶æŒè‚¡å¢åŠ ")
        elif histock_chip['big_change'] < -0.2: score -= 10; reasons.append("å¤§æˆ¶æŒè‚¡é¬†å‹•")
            
    if insider and insider > 20: score += 5; reasons.append("è‘£ç›£æŒè‚¡é«˜")
    score = max(0, min(100, score))
    
    if score >= 75: verdict = "å¼·åŠ›è²·é€² (Strong Buy)"; color = "green"
    elif score >= 55: verdict = "æŒæœ‰/è§€æœ› (Hold)"; color = "orange"
    else: verdict = "è³£å‡º/é¿é–‹ (Sell)"; color = "red"
    
    # --- æœªä¾†å±•æœ› (é‚è¼¯ç”Ÿæˆ) ---
    outlook_text = {"catalysts": [], "risks": [], "thesis": ""}
    
    # å‚¬åŒ–åŠ‘
    if histock_chip and histock_chip['big_change'] > 0: outlook_text["catalysts"].append(f"**ç±Œç¢¼æ²‰æ¾±**ï¼šå¤§æˆ¶æŒè‚¡æœ¬é€±å¢åŠ  {histock_chip['big_change']:.2f}%ï¼Œä¸»åŠ›å¸ç±Œæ˜é¡¯ã€‚")
    if adv_fin.get('GrossMargin', 0) > 40: outlook_text["catalysts"].append(f"**è­·åŸæ²³å„ªå‹¢**ï¼šæ¯›åˆ©ç‡é” {adv_fin['GrossMargin']:.1f}%ï¼Œé¡¯ç¤ºç”¢å“å…·å‚™å¼·å¤§å®šåƒ¹æ¬Šã€‚")
    if chips and chips['trust'] > 0: outlook_text["catalysts"].append("**æŠ•ä¿¡ä½œå¸³**ï¼šæŠ•ä¿¡è¿‘æœŸè²·è¶…ï¼Œå­£åº•ä½œå¸³è¡Œæƒ…å¯æœŸã€‚")
    if today['Close'] > today['MA60']: outlook_text["catalysts"].append("**å¤šé ­æ¶æ§‹**ï¼šè‚¡åƒ¹ä½æ–¼å­£ç·šä¹‹ä¸Šï¼Œé•·ç·šè¶¨å‹¢åå¤šã€‚")
    if not outlook_text["catalysts"]: outlook_text["catalysts"].append("**å€é–“éœ‡ç›ª**ï¼šç›®å‰ç¼ºä¹æ˜ç¢ºæ”»æ“Šè¨Šè™Ÿï¼Œç­‰å¾…é‡èƒ½æ”¾å¤§ã€‚")

    # é¢¨éšª
    if today['RSI'] > 75: outlook_text["risks"].append("**æŒ‡æ¨™éç†±**ï¼šRSI æŒ‡æ¨™éé«˜ï¼ŒçŸ­ç·šå¯èƒ½ä¿®æ­£ã€‚")
    if fin_data['PE'] and float(fin_data['PE']) > 35: outlook_text["risks"].append("**ä¼°å€¼åé«˜**ï¼šæœ¬ç›Šæ¯”é«˜æ–¼å¸‚å ´å¹³å‡ï¼Œéœ€ç•™æ„ä¿®æ­£é¢¨éšªã€‚")
    if not outlook_text["risks"]: outlook_text["risks"].append("**ç³»çµ±é¢¨éšª**ï¼šç•™æ„å¤§ç›¤æ³¢å‹•ã€‚")
    
    thesis_fin = 'ç²åˆ©èƒ½åŠ›å¼·å‹' if adv_fin.get('ROE',0) > 10 else 'ç²åˆ©å¹³ç©©'
    
    outlook_text["thesis"] = f"ç¶œåˆåˆ†æï¼Œ{fin_data['Name']} è©•åˆ†ç‚º **{score} åˆ†**ã€‚åŸºæœ¬é¢é¡¯ç¤º{thesis_fin}ã€‚å»ºè­°é—œæ³¨ **{verdict.split('(')[0]}**ã€‚"

    return {
        "id": stock_id, "name": fin_data['Name'], "price": today['Close'], "score": score,
        "verdict": verdict, "color": color, "reasons": reasons,
        "fin": fin_data, "chips": chips, "chip_status": chip_status,
        "insider": insider, 
        "histock_chip": histock_chip, 
        "adv_fin": adv_fin,
        "fin_source": fin_source,
        "today": today, "info": info, "zh_summary": zh_summary,
        "outlook": outlook_text
    }

# ==========================================
# ğŸ–¥ï¸ UI ä»‹é¢
# ==========================================
st.title("å¸¥å“¥åŸ AI æŠ•é¡§")
st.markdown("### ğŸš€ æ©Ÿæ§‹ç´šæŠ•è³‡åˆ†æå ±å‘Šæ›¸")

col1, col2 = st.columns([3, 1])
with col1:
    user_input = st.text_input("è¼¸å…¥ä»£ç¢¼ (ä¾‹å¦‚ 2330, 2603)", "")
with col2:
    st.write("")
    st.write("")
    run_btn = st.button("ç”Ÿæˆå ±å‘Š", use_container_width=True)

if run_btn and user_input:
    stock_code = user_input.strip().upper()
    if stock_code.isdigit(): stock_code += ".TW"
    
    with st.spinner("æŸ¥è©¢ä¸­..."):
        data = generate_full_analysis(stock_code)
        
    if data:
        st.header(f"1. åŸ·è¡Œæ‘˜è¦ï¼š{data['name']} ({stock_code})")
        m1, m2, m3, m4 = st.columns(4)
        m1.metric("ç¶œåˆä¿¡å¿µè©•åˆ†", f"{data['score']} / 100")
        m2.metric("æŠ•è³‡å»ºè­°", data['verdict'].split(' ')[0])
        m3.metric("æœ€æ–°æ”¶ç›¤åƒ¹", f"{data['price']:.2f}")
        m4.caption(f"ä¾†æºï¼šHiStock + {data['fin_source']}")
        
        st.info(f"ç³»çµ±å»ºè­°ï¼š**{data['verdict'].split('(')[0]}**ã€‚é—œéµå› ç´ ï¼š**{data['reasons'][0] if data['reasons'] else 'ä¸­æ€§'}**ã€‚")

        tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ¢ å•†æ¥­èˆ‡åŸºæœ¬é¢", "ğŸ’° è²¡å‹™èˆ‡ä¼°å€¼", "ğŸ¦ è‚¡æ¬Šèˆ‡ç±Œç¢¼", "ğŸ“ˆ æŠ€è¡“åˆ†æ", "âš–ï¸ æœªä¾†å±•æœ›èˆ‡æˆ°ç•¥"])
        
        with tab1:
            st.subheader("æ¥­å‹™èƒŒæ™¯")
            st.write(data['zh_summary'])
            st.markdown("---")
            st.caption(f"ç”¢æ¥­ï¼š{data['info'].get('sector', 'N/A')} > {data['info'].get('industry', 'N/A')}")
            
        with tab2:
            st.subheader("è²¡å‹™ç¸¾æ•ˆ (Financials)")
            
            f1, f2, f3 = st.columns(3)
            pe = f"{data['fin']['PE']:.2f}" if data['fin']['PE'] else "N/A"
            pb = f"{data['fin']['PB']:.2f}" if data['fin']['PB'] else "N/A"
            yld = f"{data['fin']['Yield']:.2f}%" if data['fin']['Yield'] else "N/A"
            f1.metric("æœ¬ç›Šæ¯” (P/E)", pe); f2.metric("è‚¡åƒ¹æ·¨å€¼æ¯” (P/B)", pb); f3.metric("æ®–åˆ©ç‡", yld)

            st.divider()
            
            st.markdown(f"#### ğŸ“Š ç²åˆ©èƒ½åŠ›èˆ‡ç¶“ç‡Ÿç¸¾æ•ˆ")
            gf = data['adv_fin']
            g1, g2, g3, g4 = st.columns(4)
            
            def fmt(v, suffix='%'): return f"{v:.2f}{suffix}" if v is not None else "N/A"
            
            g1.metric("æ¯›åˆ©ç‡", fmt(gf.get('GrossMargin')), help="è¶Šé«˜è¶Šå¥½")
            g2.metric("ç‡Ÿæ¥­åˆ©ç›Šç‡", fmt(gf.get('OpMargin')))
            g3.metric("ç¨…å¾Œæ·¨åˆ©ç‡", fmt(gf.get('NetMargin')))
            g4.metric("ROE (æ¬Šç›Šå ±é…¬)", fmt(gf.get('ROE')))
            
            st.write("")
            
            g5, g6, g7, g8 = st.columns(4)
            g5.metric("EPS (æ¯è‚¡ç›ˆé¤˜)", fmt(gf.get('EPS'), ' å…ƒ'))
            g6.metric("æ¯è‚¡æ·¨å€¼ (BPS)", fmt(gf.get('BPS'), ' å…ƒ'))
            g7.metric("ROA (è³‡ç”¢å ±é…¬)", fmt(gf.get('ROA')))
            g8.caption(f"æ•¸æ“šä¾†æºï¼š{data['fin_source']}")

        with tab3:
            st.subheader("æ‰€æœ‰æ¬Šèˆ‡äº¤æ˜“å‹•æ…‹")
            
            st.markdown("#### ğŸ“Š é›†ä¿åˆ†ä½ˆ (HiStock å—¨æŠ•è³‡)")
            if data['histock_chip']:
                hc = data['histock_chip']
                g1, g2, g3 = st.columns(3)
                g1.metric("400å¼µä»¥ä¸Šå¤§æˆ¶", f"{hc['big_percent']}%", f"{hc['big_change']:.2f}%")
                g2.metric("è‚¡æ±äººæ•¸", f"{hc['holders']} äºº", f"{hc['holders_change']} äºº", delta_color="inverse")
                g3.caption(f"çµ±è¨ˆæ—¥æœŸï¼š{hc['date']}")
                if hc['big_change'] > 0: st.success("ğŸ”¥ ç±Œç¢¼é›†ä¸­ (å¤§æˆ¶è²·)")
                elif hc['big_change'] < 0: st.error("âš ï¸ ç±Œç¢¼é¬†å‹• (å¤§æˆ¶è³£)")
            else:
                st.warning("âš ï¸ å—¨æŠ•è³‡çˆ¬èŸ²æœªæŠ“å–åˆ°è¡¨æ ¼ï¼Œå¯èƒ½ç¶²é çµæ§‹æ”¹è®Šã€‚")
            
            st.divider()
            c1, c2 = st.columns(2)
            with c1:
                st.markdown("#### ğŸ›ï¸ ä¸‰å¤§æ³•äºº")
                if data['chips']: st.json(data['chips'])
            with c2:
                st.markdown("#### ğŸ‘” å…§éƒ¨äººæŒè‚¡")
                if data['insider']: st.metric("è‘£ç›£æŒè‚¡", f"{data['insider']}%")

        with tab4:
            st.subheader("æŠ€è¡“åˆ†æ")
            t1, t2, t3 = st.columns(3)
            t1.metric("RSI (14)", f"{data['today']['RSI']:.2f}")
            t2.metric("MACD", f"{data['today']['MACD'] - data['today']['Signal']:.2f}")
            t3.metric("æœˆç·šä¹–é›¢", f"{data['price'] - data['today']['MA20']:.2f}")

        with tab5:
            st.subheader("æœªä¾†å±•æœ›èˆ‡æˆ°ç•¥å‚¬åŒ–åŠ‘")
            st.markdown(f"**åˆ†ææ—¥æœŸ**ï¼š{datetime.date.today()}")
            st.markdown("#### 1. æˆ°ç•¥å‚¬åŒ–åŠ‘")
            for i in data['outlook']['catalysts']: st.markdown(f"- {i}")
            st.markdown("#### 2. é¢¨éšªçŸ©é™£")
            for i in data['outlook']['risks']: st.markdown(f"- âš ï¸ {i}")
            st.markdown("#### 3. ç¶œåˆæŠ•è³‡è«–è¿°")
            st.info(data['outlook']['thesis'])
            st.caption("*(å…è²¬è²æ˜ï¼šæœ¬å ±å‘Šç”± AI è‡ªå‹•ç”Ÿæˆï¼Œåƒ…ä¾›åƒè€ƒ)*")

    else:
        st.error(f"âŒ æŸ¥ç„¡ä»£ç¢¼ {stock_code}")
